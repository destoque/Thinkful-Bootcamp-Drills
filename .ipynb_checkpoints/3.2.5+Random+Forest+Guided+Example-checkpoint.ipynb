{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We've talked about Random Forests. Now it's time to build one.\n",
    "\n",
    "Here we'll use data from Lending Club to predict the state of a loan given some information about it. You can find the dataset [here](https://www.lendingclub.com/info/download-data.action). We'll use 2015 data. ([Thinkful mirror](https://www.dropbox.com/s/m7z42lubaiory33/LoanStats3d.csv?dl=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Replace the path with the correct path for your data.\n",
    "y2015 = pd.read_csv(\n",
    "    'https://www.dropbox.com/s/0so14yudedjmm5m/LoanStats3d.csv?dl=1',\n",
    "    skipinitialspace=True,\n",
    "    header=1\n",
    ")\n",
    "\n",
    "# Note the warning about dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68009401</td>\n",
       "      <td>72868139.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.85%</td>\n",
       "      <td>379.39</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>298100.0</td>\n",
       "      <td>31329.0</td>\n",
       "      <td>281300.0</td>\n",
       "      <td>13400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68354783</td>\n",
       "      <td>73244544.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.49%</td>\n",
       "      <td>298.58</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88635.0</td>\n",
       "      <td>55387.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>75635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68466916</td>\n",
       "      <td>73356753.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.49%</td>\n",
       "      <td>777.55</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373572.0</td>\n",
       "      <td>68056.0</td>\n",
       "      <td>38400.0</td>\n",
       "      <td>82117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68466961</td>\n",
       "      <td>73356799.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>6.49%</td>\n",
       "      <td>858.05</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304003.0</td>\n",
       "      <td>74920.0</td>\n",
       "      <td>41500.0</td>\n",
       "      <td>42503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68495092</td>\n",
       "      <td>73384866.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>19.89%</td>\n",
       "      <td>320.99</td>\n",
       "      <td>E</td>\n",
       "      <td>E3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38998.0</td>\n",
       "      <td>18926.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>18248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  68009401  72868139.0    16000.0      16000.0          16000.0   60 months   \n",
       "1  68354783  73244544.0     9600.0       9600.0           9600.0   36 months   \n",
       "2  68466916  73356753.0    25000.0      25000.0          25000.0   36 months   \n",
       "3  68466961  73356799.0    28000.0      28000.0          28000.0   36 months   \n",
       "4  68495092  73384866.0     8650.0       8650.0           8650.0   36 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade            ...              \\\n",
       "0   14.85%       379.39     C        C5            ...               \n",
       "1    7.49%       298.58     A        A4            ...               \n",
       "2    7.49%       777.55     A        A4            ...               \n",
       "3    6.49%       858.05     A        A2            ...               \n",
       "4   19.89%       320.99     E        E3            ...               \n",
       "\n",
       "  num_tl_90g_dpd_24m num_tl_op_past_12m pct_tl_nvr_dlq  percent_bc_gt_75  \\\n",
       "0                0.0                2.0           78.9               0.0   \n",
       "1                0.0                2.0          100.0              66.7   \n",
       "2                0.0                0.0          100.0              20.0   \n",
       "3                0.0                0.0           91.7              22.2   \n",
       "4                0.0               12.0          100.0              50.0   \n",
       "\n",
       "  pub_rec_bankruptcies tax_liens tot_hi_cred_lim total_bal_ex_mort  \\\n",
       "0                  0.0       2.0        298100.0           31329.0   \n",
       "1                  0.0       0.0         88635.0           55387.0   \n",
       "2                  0.0       0.0        373572.0           68056.0   \n",
       "3                  0.0       0.0        304003.0           74920.0   \n",
       "4                  1.0       0.0         38998.0           18926.0   \n",
       "\n",
       "  total_bc_limit total_il_high_credit_limit  \n",
       "0       281300.0                    13400.0  \n",
       "1        12500.0                    75635.0  \n",
       "2        38400.0                    82117.0  \n",
       "3        41500.0                    42503.0  \n",
       "4         2750.0                    18248.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## The Blind Approach\n",
    "\n",
    "Now, as we've seen before, creating a model is the easy part. Let's try just using everything we've got and throwing it without much thought into a Random Forest. SKLearn requires the independent variables to be be numeric, and all we want is dummy variables so let's use `get_dummies` from Pandas to generate a dummy variable for every categorical colummn and see what happens off of this kind of naive approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1ba301af602f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2015\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loan_status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2015\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loan_status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1208\u001b[0m             dummy = _get_dummies_1d(data[col], prefix=pre, prefix_sep=sep,\n\u001b[0;32m   1209\u001b[0m                                     \u001b[0mdummy_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy_na\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m                                     drop_first=drop_first)\n\u001b[0m\u001b[0;32m   1211\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m         \u001b[0mdummy_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Did your kernel die? My kernel died.\n",
    "\n",
    "Guess it isn't always going to be that easy...\n",
    "\n",
    "Can you think of what went wrong?\n",
    "\n",
    "(You're going to have to reset your kernel and reload the column, BUT DON'T RUN THE MODEL AGAIN OR YOU'LL CRASH THE KERNEL AGAIN!)\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "Well, `get_dummies` can be a very memory intensive thing, particularly if data are typed poorly. We got a warning about that earlier. Mixed data types get converted to objects, and that could create huge problems. Our dataset is about 400,000 rows. If there's a bad type there its going to see 400,000 distinct values and try to create dummies for all of them. That's bad. Lets look at all our categorical variables and see how many distinct counts there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "421097\n",
      "term\n",
      "2\n",
      "int_rate\n",
      "110\n",
      "grade\n",
      "7\n",
      "sub_grade\n",
      "35\n",
      "emp_title\n",
      "120812\n",
      "emp_length\n",
      "11\n",
      "home_ownership\n",
      "4\n",
      "verification_status\n",
      "3\n",
      "issue_d\n",
      "12\n",
      "loan_status\n",
      "7\n",
      "pymnt_plan\n",
      "1\n",
      "url\n",
      "421095\n",
      "desc\n",
      "34\n",
      "purpose\n",
      "14\n",
      "title\n",
      "27\n",
      "zip_code\n",
      "914\n",
      "addr_state\n",
      "49\n",
      "earliest_cr_line\n",
      "668\n",
      "revol_util\n",
      "1211\n",
      "initial_list_status\n",
      "2\n",
      "last_pymnt_d\n",
      "25\n",
      "next_pymnt_d\n",
      "4\n",
      "last_credit_pull_d\n",
      "26\n",
      "application_type\n",
      "2\n",
      "verification_status_joint\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "categorical = y2015.select_dtypes(include=['object'])\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Well that right there is what's called a problem. Some of these have over a hundred thousand distinct types. Lets drop the ones with over 30 unique values, converting to numeric where it makes sense. In doing this there's a lot of code that gets written to just see if the numeric conversion makes sense. It's a manual process that we'll abstract away and just include the conversion.\n",
    "\n",
    "You could extract numeric features from the dates, but here we'll just drop them. There's a lot of data, it shouldn't be a huge problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert ID and Interest Rate to numeric.\n",
    "y2015['id'] = pd.to_numeric(y2015['id'], errors='coerce')\n",
    "y2015['int_rate'] = pd.to_numeric(y2015['int_rate'].str.strip('%'), errors='coerce')\n",
    "\n",
    "# Drop other columns with many unique variables\n",
    "y2015.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util',\n",
    "            'sub_grade', 'addr_state', 'desc'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonder what was causing the dtype error on the id column, which _should_ have all been integers? Let's look at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2015.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove two summary rows at the end that don't actually contain data.\n",
    "y2015 = y2015[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now this should be better. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(y2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "It finally works! We had to sacrifice sub grade, state address and description, but that's fine. If you want to include them you could run the dummies independently and then append them back to the dataframe.\n",
    "\n",
    "## Second Attempt\n",
    "\n",
    "Now let's try this model again.\n",
    "\n",
    "We're also going to drop NA columns, rather than impute, because our data is rich enough that we can probably get away with it.\n",
    "\n",
    "This model may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The score cross validation reports is the accuracy of the tree. Here we're about 98% accurate.\n",
    "\n",
    "That works pretty well, but there are a few potential problems. Firstly, we didn't really do much in the way of feature selection or model refinement. As such there are a lot of features in there that we don't really need. Some of them are actually quite impressively useless.\n",
    "\n",
    "There's also some variance in the scores. The fact that one gave us only 93% accuracy while others gave higher than 98 is concerning. This variance could be corrected by increasing the number of estimators. That will make it take even longer to run, however, and it is already quite slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRILL: Third Attempt\n",
    "\n",
    "So here's your task. Get rid of as much data as possible without dropping below an average of 90% accuracy in a 10-fold cross validation.\n",
    "\n",
    "You'll want to do a few things in this process. First, dive into the data that we have and see which features are most important. This can be the raw features or the generated dummies. You may want to use PCA or correlation matrices.\n",
    "\n",
    "Can you do it without using anything related to payment amount or outstanding principal? How do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
